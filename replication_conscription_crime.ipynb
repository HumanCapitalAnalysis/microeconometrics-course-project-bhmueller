{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Microeconometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Benedikt Heinrich Müller, M.Sc. in Economics, Course Microeconometrics, Prof. Dr. Eisenhauer, University of Bonn, Summer term 2020\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory Remarks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following I replicate the findings of the 2011 empirical study \"*Conscription and Crime: Evidence from the Argentine Draft Lottery*\" by Galiani et al. (for exact citation see [section 1](#1.-Brief-Summary-of-the-Journal-Acticle)). Throughout I apply the same nomenclatur as did Galiani et al. (2011), i.e. the tables and figures are enumerated as in the original paper. That is to foster comparability. The data set was well preprocessed. Therefore, replication of the results was straightforward and, hence, I replicate all the empirical figures contained in the paper and the online appendix. <br>\n",
    "Galiani et al. (2011) used Stata for their analysis. Since Stata was not available to me, I collected the labels of the variables by means of comparison of the .do-file and the results presented in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content of this Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Brief Summary of the Journal Article](#1.-Brief-Summary-of-the-Journal-Acticle)\n",
    "\n",
    "    1.1 [Background & Data](#1.1-Background-&-Data)\n",
    "    \n",
    "    1.2 [Empirical Strategy](#1.2-Empirical-Strategy)\n",
    "\n",
    "2. [Replication of Key Findings](#2.-Replication-of-Key-Findings)\n",
    "\n",
    "    2.1 [Main Results](#2.1-Main-Results)\n",
    "    \n",
    "    2.2 [Complementary Results](#2.2-Complementary-Results)\n",
    "    \n",
    "    2.3 [Online Appendix](#2.3-Online-Appendix)\n",
    "    \n",
    "3. [Extensions](#3.-Extensions)\n",
    "\n",
    "    3.1 [Extended \"Testing\" of Exogeneity of Instrument](#3.1-Extended-\"Testing\"-of-Exogeneity-of-Instrument)\n",
    "\n",
    "4. [Critical Assessment of Quality](#4.-Critical-Assessment-of-Quality)\n",
    "\n",
    "[References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from linearmodels import IV2SLS\n",
    "from statsmodels.iolib.summary2 import summary_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda env remove --name student_project_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! type environment_project.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do I need to add this to the environment file.\n",
    "#conda install -c conda-forge linearmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Brief Summary of the Journal Acticle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full citation:\n",
    "\n",
    "Galiani, Sebastian, Martín A. Rossi, and Ernesto Schargrodsky. 2011. \"Conscription and Crime: Evidence from the Argentine Draft Lottery.\" *American Economic Journal: Applied Economics*, 3 (2): 119-36.\n",
    "[DOI: 10.1257/app.3.2.119](http://dx.doi.org/10.1257/app.3.2.119)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Do they use individ.-level data? Yes, but they aggregate the data to the level of identical last three digits of the ID.\n",
    " - When did the cohorts 1958-1962 serve in the military?\n",
    " - Novel feature: Authors study effect of peacetime vs war-time military service on crimerate.\n",
    " - Crimerate is the same on the cohort-ID-level for each individ.\n",
    " - The authors study the effect of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Background & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conscription in Argentina has been subject to a draft lottery until the abolishment of mandatory conscription in the 1990s. Galiani et al. use this random assignment to estimate the causal effect of serving in the military on subsequent criminal behaviour. The more important parts of the analysis use data from cohorts 1958 to 1962 (= *core cohorts*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Argentine Draft Lottery "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timing is as follows:\n",
    "1. In an open session in the month of (?) the draft numbers are drawn. For every combination of the last three numbers of the national ID of all men in the birth cohort there is a draft number between 1 and 1,000 drawn.\n",
    "2. The results of the lottery are publicly announced.\n",
    "3. Medical examinations of all individuals in the birth cohort are conducted.\n",
    "4. The exact cutoff number is publicly announced.\n",
    "5. In the month of (?) individuals with a draft number higher than the cutoff which have passed the medical examination are drafted into the military.\n",
    "6. Draftees serve in (?) the following year. Draftees start service with 21 years (core cohorts of the analysis).\n",
    "\n",
    "To avoid confusion, note that in Angrist (1990) an individual was draft eligible if he had a number *smaller* than the cutoff. In the Argentine draft lottery the draft number needed to be *higher* than the cutoff.\n",
    "\n",
    "The draft age was changed from 18 to 21 in 1955. Thus, the cohorts of 1956 and 1957 were not drafted into the military. Data on draft numbers are available for the cohorts from 1929 to 1965. Later the system of the lottery changes, to the effect that Galinai et al. (2011) could no longer determine which draft numbers were draft eligible. The cohort of 1976 was interesting, since this cohort was not drafted at all due to the abolishment of conscription in Argentina. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### War and Peace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The novelty of the study by Galiani et al. is that they not only estimate the effects of conspcription in wartime but also in peacetime. This is important out of two reasons: 1. the effects of conscription may differ on whether one served during war or peace and 2. peacetime service is more common than wartime service.\n",
    "\n",
    "1. The effect of serving in the military may be quite different when exposed to actual combat. Those individuals envolved in combat may suffer from detrimental effects on their mental and physical health. These conditions may have a large impact on their subsequent criminal behaviour after serving in the military and may also lessen labour market outcomes.\n",
    "\n",
    "2. Conscription during peacetime is more often the case than conscription during wartime. Galiani et al. note that most countries in the world have citizens drafted into military during peacetime. Thus, the effect of serving in the military in peacetime is the more relevant case when evaluating this policy.\n",
    "\n",
    "From April to June 1982 there was the *Falklands War* between Argentina and the United Kingdom. The cohorts of 1962 and 1963 served during this war. Because of data availability, the authors considered the cohorts from 1958 to 1962 for their main analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data & Important Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galiani et al. use data provided by various Argentine administrative records.\n",
    "Because of data privacy issues, they do not provide the raw data of their analysis. One observation in the data set stands for all individuals in the same birth cohort *c* and share the same last three digits of the national ID *i*.\n",
    "\n",
    "\n",
    "In the following, I describe the most important variables used in the analysis.\n",
    "The measure of criminal behaviour is the variable *crime rate*, which is also the dependent variable.\n",
    "Let *n* be the number of individuals *j* in birth cohort *c*, with the same last three digits of their national ID *i*. Further, let $I(j)$ be an identity function returning *1* if individual *j* has a criminal record, and *0* otherwise. Then, *crime rate* is defined as\n",
    "$$crimerate=\\frac{ \\sum_{j=1}^n I(j)}{n}$$\n",
    "Note, that $I(j)$ does not indicate which kind of or how many crimes individual *j* commited. <br>\n",
    "The variable whose effect the authors want to isolate is *conscription*, represented in the data set by *'sm'* (probably from Spanish *servicio militar*). *Conscription* is the share of individuals in *c* and *i* who served in the military. *Conscription* is probably endogenous and therefore instrumented for.\n",
    "The potential instrument is the variable *draft eligible*, denoted in the data set by the dummy *'highnumber'*, which returns *1* if the draft number of *c* and *i* is above the cutoff number. The variable *draft number* is also available.\n",
    "Potential control variables used are birth-cohort, origin (*argentine*, *naturalized*, and *indigenous*), and province dummies (federal states). The latter are denoted *dist* plus a number indicating one of the 24 provinces. The varible *malvinas* (Spanish name of the Falkland Islands) is a dummy which returns *1* if indidviduals of the cohort *c* served during the *Falklands War* in 1982 (for the main analysis only cohort 1962 served during the war)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Empirical Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal Graph Representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start the discussion of the empirical strategy by presenting the causal relationship Galiani et al. assumed in their study. To this end, I use the graphical representation suggested by Pearl (2014).\n",
    "\n",
    "- Put navy and hn_malvinas into DAG.\n",
    "- DAG: bdp and fd identification; fig. 4.9 b. in WM\n",
    " - Why we cannot use bd identification\n",
    "- Subtle confounding: direct self-selection, accurate perception of individual treatment effect\n",
    " - Selection on unobs.: combi. of treatment effect heterogeneity and self-selection\n",
    "- All back-door paths to be blocked that go from Z to D. See Nick Huntington-Klein.\n",
    "- Empirical concern: $E[Z|\\epsilon]$ perhaps not defendable.\n",
    "- Implicit assump.: navy service same as air force and army on crime rates except for duration!\n",
    "- Since delaying conscription is allowed if completion of studies necessary it can be argued that there is no effect via schooling?\n",
    " - starting uni just to delay military service a problem?\n",
    "- Deferemt of military service: draft eligible status did not change (was still in cohort-ID group of initial draft lottery)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, potential issues concerning the identification of the causal relationship and its crucial assumptions are discussed.\n",
    "\n",
    "Galina et al. want to study the effect of serving in the military on subsequent criminal behaviour. They want to estimate the following regression (p.127). Note that the notation presented here does not coincide with the one presented in the article. I adopted the notation used by Winship and Morgan (2007): $$Y_{ci} = \\alpha + \\delta D_{ci} + \\gamma_{c} + \\epsilon_{ci}$$\n",
    "where\n",
    "- $Y_{ci}$ denotes *crime rate*,\n",
    "- $D$, denotes *conscription*,\n",
    "- $\\delta$, is the ATE,\n",
    "- $\\gamma_{c}$, a cohort effect, and\n",
    "- $\\epsilon_{ci}$, an error term.\n",
    "\n",
    "Formally this amounts to  the following:\n",
    "$$E[Y_{ci}] = E[\\alpha + \\delta D_{ci} + \\gamma_{c} + \\epsilon_{ci}]$$\n",
    "\n",
    "If the assumption $E[\\epsilon∣D]=0$ holds, that is the variable of interest is independent of the outcome variable, we can successfully identify the causal effect of $D$ on $Y$ as the average treatment effect.\n",
    "But, in the above described setting (see causal graph) it is possible that being actually drafted into the military is subject to some form of selection. Recall that all individuals in birth cohort *c* needed to attend medical examinations.\n",
    "Failing the medical examination could be correlated with the socioeconomic background one has. There are various studies suggesting that health and socioeconomic status are associated (cite!). On the other hand, individuals with a high draft number, i.e. with a high probability of being drafted into the military, fail the medical examinations by purpose and are not being drafted into the military. One could imagine that well-placed individuals are more able to do so than individuals from other socioeconomic backgrounds. This renders *conscription* endogeneous.\n",
    "\n",
    "Hence, we cannot ensure that $E[\\epsilon∣D]=0$\n",
    "This endogeneity issue can be partially overcome by using an IV approach. A valid instrument needs to necessarily fulfil the following two conditions (this specification applies for the case of a binary instrument):\n",
    "1. Exogeneity: $E[\\epsilon∣Z]=0$\n",
    "2. Relevance: $E[Z∣D]\\neq 0$\n",
    "\n",
    "After some manipulation we arrive at the Wald estimator\n",
    "$$\\hat{\\delta}_{IV, Wald} = \\frac{E[Y|Z=1]-E[Y∣Z=0]}{E[D|Z=1]-E[D|Z=0]}$$\n",
    "\n",
    "The exogeneity condition cannot be tested statistically. One can only argue whether an instrument is uncorrelated to the error $\\epsilon$. Condition 2 can be tested by means of estimating the effect from the instrument to the endogenous independent variable $D$. The effect needs to be large and statistically significant. Otherwise we would end up with a weak instrument, which would render the IV estimator useless.\n",
    "\n",
    "In what follows, I employ the Potential Outcome framework as presented in Winship and Morgan (2007, pp. 78) in order to clarify the empirical stragtegy the paper is based upon.\n",
    "\n",
    "Potential Outcome framework & LATE.\n",
    "\n",
    "Consider the potential outcome model presented by Winship and Morgan (2007, pp. 200):\n",
    "$$Y = Y^0 + (Y^1 − Y^0)D$$\n",
    "Let $\\delta = Y^1 − Y^0$, then\n",
    "$$Y = Y^0 + \\delta D$$\n",
    "$$Y = E[Y^0] + \\delta D + Y^0−E[Y^0]$$\n",
    "\n",
    "Imbens and Angrist (1994) defined variables indicating potential treatment assignment conditional on the instrument $D^{Z=z}$. These summarise all possible behavioural responses to the instrument and allow the definition of a latent variable $C$. The follwoing is taken from Winship and Morgan (2007, p. 201):\n",
    "\n",
    "- Compliers $(C=c)$: $D^{Z=0}=0$ and $D^{Z=0}=1$\n",
    "- Defiers $(C=d)$: $D^{Z=0}=1$ and $D^{Z=0}=0$\n",
    "- Always takers $(C=a)$: $D^{Z=0}=1$ and $D^{Z=0}=1$\n",
    "- Never takers $(C=n)$: $D^{Z=0}=0$ and $D^{Z=0}=0$\n",
    "\n",
    "*Compliers* react to being exposed to the instrument by selecting into the treatment. *Always takers* select into treatment and *Never takers* never do so, irrespective of the instrument. *Defiers* would have selected into the treatment if not exposed to the instrument, but do not do so if exposed to the instrument. Being exposed to the instrument means $Z=1$ for the individual.\n",
    "\n",
    "Following Winship and Morgan (2007, p. 201), $D$ can be defined as:\n",
    "$$D = D^{Z=0} + (D^{Z=1} − D^{Z=0})Z$$\n",
    "Let $\\kappa = D^{Z=1} − D^{Z=0}$, then\n",
    "$$D = D^{Z=0} + \\kappa Z$$\n",
    "\n",
    "$\\kappa$ represents the causal effect of $Z$ on $D$. If $D$ varies for the individuals, so does $\\kappa$.\n",
    "\n",
    "Additionally to the analogous identifying conditions defined above we have athird condition. Monotonicity requires that $\\kappa ≥ 0$ for all i or $\\kappa ≤ 0$ for all i.\n",
    "\n",
    "In the light of essential individual heterogeneity, the IV results cannot be interpreted as an ATE, i.e. $\\delta$ is not constant in the population. This is the case, since we can only make statements about the causal relationship of individuals whose probability of treatment changes according to the IV. In the empirical investigation at hand this means that the estimated effect is the effect on the compliers only, i.e. the individuals who join the military because they are coerced of doing so by having a draft number higher than the cutoff. That is, the Wald estimator in this context converges in probabilty to $E[\\delta |C=c]$ (Winship and Morgan 2007, p. 202).\n",
    "\n",
    "This treatment affect is denoted the *Local Average Tretament Effect* (LATE), introduced by Angrist and Imbens (1994). The additional condition of monotonicity implies that there are either compliers or defiers in the sample, but not both. In the problem at hand this amounts to assuming that there are no draft-lottery defiers in the sample. A draft-lottery defier is a person that would have served voluntarily, i.e. if he wasn't assigned a draft number above the cutoff, but abstains from military service if he got a draft number above the cutoff. To avoid military service, if one was assigned a number above the cutoff, it is necessary to fail the medical examination, what might come with some effort. Thus, one can argue that there are no defiers in the sample, i.e. people who had served if service was voluntary, but who did not if they were drafted.\n",
    "Moreover, the treatment effect of the analysis is only provided for the draft-lottery compliers, since, given monotonicity, only these are the ones having an impact on the estimates of the effect on crime rates. Recall that treatment status did not change for *Never takers* and *always takers*. Thus, all the variation in estimating the causal effect in an IV setting is due to compliers (Winship and Morgan 2007, p. 203).\n",
    "Thus, $\\delta$ is not constant.\n",
    "\n",
    "Policy relevance of the instrument. We are fine, since we also test the draft lottery as a policy.\n",
    "See Heckman (1997). The effect the paper by Galinai et al. (2011) wants to evaluate is in fact the effect of compulsory military service on crime rates, not the average treatment effect of serving in the military per se. The precise question they ask is whether conscription should be implemented in order to lower crime rates. The effect they find is the effect on individuals that were induced to serve due to the draft lottery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Replication of Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call out which of the findings are really key.\n",
    " - Exclusion restriction met? Can only argue that this holds.\n",
    " - Relevancy ensured?\n",
    " - Direction of bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data from .dta-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Stata file into a pandas DataFrame: Crime.dta\n",
    "path = ('data/Crime.dta')\n",
    "df = pd.read_stata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the regressions below, add a constant to the data frame.\n",
    "df['constant'] = 1\n",
    "# Get a variable representing the string constant.\n",
    "constant = ['constant']\n",
    "# Same for 'highnumber' and 'sm'.\n",
    "highnumber = ['highnumber']\n",
    "conscription = ['sm']\n",
    "crimerate = ['crimerate']\n",
    "malvinas = ['malvinas']\n",
    "navy = ['navy']\n",
    "# Get list of origin dummy names. Omit 'argentine' i.o.t. avoid multicollinearity.\n",
    "origin = ['naturalized', 'indigenous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of cohort dummy names.\n",
    "cohort_years = list(range(1930, 1966, 1))  # Omit cohort_1929 (multicollinearity).\n",
    "cohorts = []\n",
    "for i in cohort_years:\n",
    "    cohorts.append('cohort_' + f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of district dummy names. District dummies have already been provided in data.\n",
    "district_numbers = list(range(2, 25, 1))  # Omit dist1 (multicollinearity).\n",
    "districts = []\n",
    "for i in district_numbers:\n",
    "    districts.append('dist' + f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas' .get_dummies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cohort dummies.\n",
    "# Define a function that creates a dummy for a given cohort.\n",
    "def get_cohort_dummy(df, col, c):\n",
    "    '''\n",
    "    Inputs are\n",
    "    a DataFrame,\n",
    "    a column col (string), and\n",
    "    an input c (cohort) for which the output variable shall return 1.\n",
    "    newcol\n",
    "    '''\n",
    "    # Create name of column for cohort c.\n",
    "    newcol = 'cohort_' + f'{c}'\n",
    "    # Define a function that creates a dummy var. conditional on another column.\n",
    "    def dummy_mapping(x):\n",
    "        if x == c:\n",
    "            return 1\n",
    "        elif x == np.nan:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return 0\n",
    "    df[newcol] = df[col].apply(dummy_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate variable hn_malvinas: inteaction term between highnumber and malvinas.\n",
    "df['hn_malvinas'] = df.highnumber*df.malvinas\n",
    "hn_malvinas = ['hn_malvinas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cohort_dummy(df=df, col='cohort', c=1927)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49000\n",
       "1     1000\n",
       "Name: cohort_1927, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cohort_1927'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean         0.020000\n",
       "std          0.140001\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: cohort_1927, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cohort_1927'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cohort</th>\n",
       "      <th>1927.0</th>\n",
       "      <th>1928.0</th>\n",
       "      <th>1929.0</th>\n",
       "      <th>1930.0</th>\n",
       "      <th>1931.0</th>\n",
       "      <th>1932.0</th>\n",
       "      <th>1933.0</th>\n",
       "      <th>1934.0</th>\n",
       "      <th>1935.0</th>\n",
       "      <th>1936.0</th>\n",
       "      <th>1937.0</th>\n",
       "      <th>1938.0</th>\n",
       "      <th>1939.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort_1927</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cohort       1927.0  1928.0  1929.0  1930.0  1931.0  1932.0  1933.0  1934.0  \\\n",
       "cohort_1927                                                                   \n",
       "0                 0    1000    1000    1000    1000    1000    1000    1000   \n",
       "1              1000       0       0       0       0       0       0       0   \n",
       "\n",
       "cohort       1935.0  1936.0  1937.0  1938.0  1939.0  \n",
       "cohort_1927                                          \n",
       "0              1000    1000    1000    1000    1000  \n",
       "1                 0       0       0       0       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.cohort_1927, df.cohort[df.cohort < 1940][df.cohort > 1920])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels='cohort_1927', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cohort dummies from 1929 to 1965. Alternatively use OneHotEncoding.\n",
    "for year in list(range(1929, 1966, 1)):\n",
    "    get_cohort_dummy(df=df, col='cohort', c=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnumber</th>\n",
       "      <th>cohort</th>\n",
       "      <th>draftnumber</th>\n",
       "      <th>navy</th>\n",
       "      <th>malvinas</th>\n",
       "      <th>military</th>\n",
       "      <th>crimerate</th>\n",
       "      <th>cl_claselow2</th>\n",
       "      <th>falselow2</th>\n",
       "      <th>formal</th>\n",
       "      <th>...</th>\n",
       "      <th>cohort_1956</th>\n",
       "      <th>cohort_1957</th>\n",
       "      <th>cohort_1958</th>\n",
       "      <th>cohort_1959</th>\n",
       "      <th>cohort_1960</th>\n",
       "      <th>cohort_1961</th>\n",
       "      <th>cohort_1962</th>\n",
       "      <th>cohort_1963</th>\n",
       "      <th>cohort_1964</th>\n",
       "      <th>cohort_1965</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idnumber  cohort  draftnumber  navy  malvinas  military  crimerate  \\\n",
       "0       0.0  1927.0        445.0   0.0         0       0.0   0.064294   \n",
       "1       1.0  1927.0        397.0   0.0         0       0.0   0.027555   \n",
       "2       2.0  1927.0        659.0   0.0         0       0.0   0.036739   \n",
       "3       3.0  1927.0        781.0   0.0         0       0.0   0.045924   \n",
       "4       4.0  1927.0        205.0   0.0         0       0.0   0.018370   \n",
       "\n",
       "   cl_claselow2  falselow2  formal  ...  cohort_1956  cohort_1957  \\\n",
       "0           1.0        NaN     NaN  ...            0            0   \n",
       "1           1.0        NaN     NaN  ...            0            0   \n",
       "2           1.0        NaN     NaN  ...            0            0   \n",
       "3           1.0        NaN     NaN  ...            0            0   \n",
       "4           1.0        NaN     NaN  ...            0            0   \n",
       "\n",
       "   cohort_1958  cohort_1959  cohort_1960  cohort_1961  cohort_1962  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   cohort_1963  cohort_1964  cohort_1965  \n",
       "0            0            0            0  \n",
       "1            0            0            0  \n",
       "2            0            0            0  \n",
       "3            0            0            0  \n",
       "4            0            0            0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Main Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get [back to top](#Content-of-this-Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1 - Availability of Data by Birth Cohort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1 on p. xxy gives an overview of the data available to the authors. The 2SLS approach uses the data o the years 1958 through 1962, since for these cohorts data on actual conscription status is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2 - Differences in Pre-Treatment Characteristics by Birth Cohort and Eligibility Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe changing nan_policy yields correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.07953373199691331, pvalue=0.9366708296999757)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get statistics for cohort 1958 for argentine.\n",
    "a = df.argentine[df.highnumber == 0][df.cohort == 1958]\n",
    "b = df.argentine[df.highnumber == 1][df.cohort == 1958]\n",
    "stats.ttest_ind(a, b, axis=0, equal_var=False, nan_policy='propagate')\n",
    "# equal_var = False since the authors allow for unequal variances across the groups. Why is this good practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.14980859455270507, pvalue=0.8810374950973898)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get statistics for cohort 1958 for indigenous.\n",
    "a = df.indigenous[df.highnumber == 0][df.cohort == 1958]\n",
    "b = df.indigenous[df.highnumber == 1][df.cohort == 1958]\n",
    "stats.ttest_ind(a, b, axis=0, equal_var=False, nan_policy='propagate')\n",
    "# equal_var = False since the authors allow for unequal variances across the groups. Why is this good practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Argentine\n",
      "Cohort 1958: t-statistic = -0.0795, standard error = -0.0849\n",
      "p-value: 0.9367\n",
      "Cohort 1959: t-statistic = -0.1376, standard error = -0.1545\n",
      "p-value: 0.8906\n",
      "Cohort 1960: t-statistic = -1.0550, standard error = -3.6150\n",
      "p-value: 0.2918\n",
      "Cohort 1961: t-statistic = -0.1874, standard error = -0.2201\n",
      "p-value: 0.8514\n",
      "Cohort 1962: t-statistic = 0.2661, standard error = 0.3367\n",
      "p-value: 0.7903\n",
      "***\n",
      "Indigenous\n",
      "Cohort 1958: t-statistic = -0.1498, standard error = -0.1700\n",
      "p-value: 0.8810\n",
      "Cohort 1959: t-statistic = -0.1539, standard error = -0.1754\n",
      "p-value: 0.8777\n",
      "Cohort 1960: t-statistic = 0.7176, standard error = 1.5162\n",
      "p-value: 0.4733\n",
      "Cohort 1961: t-statistic = -0.4717, standard error = -0.7402\n",
      "p-value: 0.6373\n",
      "Cohort 1962: t-statistic = 0.6425, standard error = 1.2338\n",
      "p-value: 0.5208\n",
      "***\n",
      "Naturalized\n",
      "Cohort 1958: t-statistic = 0.7054, standard error = 1.4657\n",
      "p-value: 0.4813\n",
      "Cohort 1959: t-statistic = 0.1514, standard error = 0.1721\n",
      "p-value: 0.8797\n",
      "Cohort 1960: t-statistic = 0.9337, standard error = 2.6615\n",
      "p-value: 0.3508\n",
      "Cohort 1961: t-statistic = 0.7330, standard error = 1.5805\n",
      "p-value: 0.4638\n",
      "Cohort 1962: t-statistic = -0.8793, standard error = -2.3165\n",
      "p-value: 0.3796\n"
     ]
    }
   ],
   "source": [
    "# Now in a for loop.\n",
    "cohort = list(range(1958, 1963, 1))\n",
    "for d in ['argentine', 'indigenous', 'naturalized']:\n",
    "    print('***')\n",
    "    print(f'{d.capitalize()}')\n",
    "    for c in cohort:\n",
    "        a = df[d][df.highnumber == 0][df.cohort == c]\n",
    "        b = df[d][df.highnumber == 1][df.cohort == c]\n",
    "        ttest = stats.ttest_ind(a, b, axis=0, equal_var=False, nan_policy='propagate')\n",
    "        tstat = ttest.statistic\n",
    "        pval = ttest.pvalue\n",
    "        standard_error = tstat/pval\n",
    "        print(f'Cohort {c}: t-statistic = {tstat:.4f}, standard error = {standard_error:.4f}')\n",
    "        print(f'p-value: {pval:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3 - First Stage by Birth Cohort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3 column (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cohort_1959', 'cohort_1960', 'cohort_1961', 'cohort_1962']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohorts[29: 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Define endogenous and exogenous data.\n",
    "# Due to multicollinearity issues leave out dummy for '58\n",
    "indep_vars = [highnumber + cohorts[29: 33] + constant]\n",
    "df_regression = df[df.cohort > 1957][df.cohort < 1963].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 91)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_regression[highnumber + cohorts[29: 33] + constant].copy()\n",
    "y = df_regression.loc[:, 'sm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter values:\n",
      "highnumber     0.6587\n",
      "cohort_1959   -0.0191\n",
      "cohort_1960   -0.0001\n",
      "cohort_1961    0.0483\n",
      "cohort_1962    0.0201\n",
      "constant       0.0323\n",
      "dtype: float64\n",
      "White robust standard errors:\n",
      "highnumber     0.0012\n",
      "cohort_1959    0.0024\n",
      "cohort_1960    0.0018\n",
      "cohort_1961    0.0017\n",
      "cohort_1962    0.0019\n",
      "constant       0.0017\n",
      "dtype: float64\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Fit and summarise OLS model.\n",
    "model = sm.OLS(y, X)  # Use the implementation of R when reconsidering this code.\n",
    "\n",
    "rslts = model.fit()\n",
    "\n",
    "df_regression['fitted_conscription'] = rslts.fittedvalues\n",
    "#print(rslts.summary())\n",
    "print('Parameter values:')\n",
    "print(round(rslts.params, 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('White robust standard errors:')\n",
    "print(round(rslts.HC0_se, 4))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highnumber</th>\n",
       "      <th>cohort</th>\n",
       "      <th>sm</th>\n",
       "      <th>fitted_conscription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.665339</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31002</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.660793</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.676991</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31005</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31009</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31010</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.710784</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31011</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31012</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31014</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31016</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31019</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       highnumber  cohort        sm  fitted_conscription\n",
       "31000         0.0  1958.0  0.044118             0.032299\n",
       "31001         1.0  1958.0  0.665339             0.691045\n",
       "31002         1.0  1958.0  0.660793             0.691045\n",
       "31003         1.0  1958.0  0.676991             0.691045\n",
       "31004         0.0  1958.0  0.055794             0.032299\n",
       "31005         1.0  1958.0  0.689815             0.691045\n",
       "31006         0.0  1958.0  0.032787             0.032299\n",
       "31007         1.0  1958.0  0.648649             0.691045\n",
       "31008         1.0  1958.0  0.706977             0.691045\n",
       "31009         1.0  1958.0  0.741228             0.691045\n",
       "31010         1.0  1958.0  0.710784             0.691045\n",
       "31011         1.0  1958.0  0.686747             0.691045\n",
       "31012         1.0  1958.0  0.681416             0.691045\n",
       "31013         1.0  1958.0  0.694323             0.691045\n",
       "31014         1.0  1958.0  0.699115             0.691045\n",
       "31015         0.0  1958.0  0.045455             0.032299\n",
       "31016         1.0  1958.0  0.736842             0.691045\n",
       "31017         0.0  1958.0  0.065789             0.032299\n",
       "31018         0.0  1958.0  0.045045             0.032299\n",
       "31019         0.0  1958.0  0.045833             0.032299"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regression[['highnumber', 'cohort', 'sm', 'fitted_conscription']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3 column (2) - (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cohort 1958\n",
      "**************************************************\n",
      "highnumber    0.6279\n",
      "constant      0.0578\n",
      "dtype: float64\n",
      "highnumber    0.0033\n",
      "constant      0.0030\n",
      "dtype: float64\n",
      "\n",
      " Cohort 1959\n",
      "**************************************************\n",
      "highnumber    0.6210\n",
      "constant      0.0389\n",
      "dtype: float64\n",
      "highnumber    0.0027\n",
      "constant      0.0008\n",
      "dtype: float64\n",
      "\n",
      " Cohort 1960\n",
      "**************************************************\n",
      "highnumber    0.6505\n",
      "constant      0.0377\n",
      "dtype: float64\n",
      "highnumber    0.0018\n",
      "constant      0.0008\n",
      "dtype: float64\n",
      "\n",
      " Cohort 1961\n",
      "**************************************************\n",
      "highnumber    0.6972\n",
      "constant      0.0556\n",
      "dtype: float64\n",
      "highnumber    0.0017\n",
      "constant      0.0011\n",
      "dtype: float64\n",
      "\n",
      " Cohort 1962\n",
      "**************************************************\n",
      "highnumber    0.6853\n",
      "constant      0.0343\n",
      "dtype: float64\n",
      "highnumber    0.0019\n",
      "constant      0.0007\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define endogenous and exogenous data.\n",
    "years = list(range(1958, 1963, 1))\n",
    "for i in years:\n",
    "    df_regression = df[df.cohort == i].copy()\n",
    "    X = df_regression[['highnumber', 'constant']].copy()\n",
    "    y = df_regression.loc[:, 'sm']\n",
    "    # Fit and summarise OLS model.\n",
    "    OLS = sm.OLS(y, X)  # Use the implementation of R when reconsidering this code.\n",
    "    rslts = OLS.fit()\n",
    "    #print()\n",
    "    print(f'\\n Cohort {i}')\n",
    "    print(50*'*')\n",
    "    print(round(rslts.params, 4))  # Get array of these values (not rounded) by adding .values.\n",
    "    print(round(rslts.HC0_se, 4))  # These are White’s (1980) heteroskedasticity robust standard errors.\n",
    "    #Same used by Galiani et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discuss rregression results. Note on validity of the instrument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4 - Estimated Impact of Conscription on Crime Rates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 4 column (1) - (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_reg = df[df.cohort > 1957][df.cohort < 1963].copy()\n",
    "# Dependent variable: Crime rate\n",
    "y = df_reg.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get set of independent variables.\n",
    "# 'no_controls' refers to the case where we have cohort controls only.\n",
    "\n",
    "vars_controls = highnumber + cohorts[29: 33] + origin + districts + constant\n",
    "vars_no_controls = highnumber + cohorts[29: 33] + constant\n",
    "\n",
    "X_controls = df_reg[vars_controls].copy()\n",
    "X_no_controls = df_reg[vars_no_controls].copy()\n",
    "# In statsmodels we need to add a constant by hand:\n",
    "#X_controls = sm.add_constant(X_controls, prepend=False)\n",
    "#X_no_controls = sm.add_constant(X_no_controls, prepend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. OLS Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: What does the 'absorb' attribute in Stata areg mean? Do I need to take this into account?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (1): Independent variable is *Draft eligible* (highnumber)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results. Cohort controls only.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.0018\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0006\n"
     ]
    }
   ],
   "source": [
    "OLS = sm.OLS(y, X_no_controls)  # Use the implementation of R when reconsidering this code.\n",
    "rslts = OLS.fit()\n",
    "print(f'OLS Results. Cohort controls only.')\n",
    "#print()\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params[0], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "#print()\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (2): Independent variable is *Draft eligible* (highnumber). Controls for origin and district included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results. Cohort, origin and district controls included.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.0018\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0006\n"
     ]
    }
   ],
   "source": [
    "OLS = sm.OLS(y, X_controls)  # Use the implementation of R when reconsidering this code.\n",
    "rslts = OLS.fit()\n",
    "print(f'OLS Results. Cohort, origin and district controls included.')\n",
    "#print()\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params[0], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "#print()\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. 2SLS Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (3): Independent variable is *Conscription* (sm), instrumented by *Draft Eligible* (highnumber)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2SLS Results. Cohort controls only.\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:              crimerate   R-squared:                      0.0038\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.0028\n",
      "No. Observations:                5000   F-statistic:                    21.804\n",
      "Date:                Mon, Jul 13 2020   P-value (F-stat)                0.0006\n",
      "Time:                        19:34:32   Distribution:                  chi2(5)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "constant        0.0674     0.0008     89.905     0.0000      0.0660      0.0689\n",
      "cohort_1959    -0.0007     0.0008    -0.8735     0.3824     -0.0023      0.0009\n",
      "cohort_1960     0.0003     0.0008     0.4051     0.6854     -0.0012      0.0019\n",
      "cohort_1961     0.0010     0.0008     1.2544     0.2097     -0.0006      0.0026\n",
      "cohort_1962     0.0018     0.0008     2.2257     0.0260      0.0002      0.0034\n",
      "sm              0.0027     0.0008     3.1688     0.0015      0.0010      0.0043\n",
      "===============================================================================\n",
      "\n",
      "Endogenous: sm\n",
      "Instruments: highnumber\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "iv = IV2SLS(y, df_reg[constant + cohorts[29: 33]], df_reg['sm'], df_reg['highnumber'])\n",
    "# Input of IV2SLS: dependent, exog, endog, instruments, *, weights=None\n",
    "rslts = iv.fit()\n",
    "print(f'2SLS Results. Cohort controls only.')\n",
    "print(rslts)  # By default White standard errors.\n",
    "#print('Coefficient estimate for Conscription (sm).')\n",
    "#print(round(rslts.params[0], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "#print()\n",
    "#print('White robust standard error Conscription (sm).')\n",
    "#print(round(rslts.HC0_se[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (4): Independent variable is *Conscription* (sm), instrumented by *Draft Eligible* (highnumber). Controls for origin and district included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2SLS Results. Cohort, origin and district controls included.\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:              crimerate   R-squared:                      0.0181\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.0121\n",
      "No. Observations:                5000   F-statistic:                    95.774\n",
      "Date:                Mon, Jul 13 2020   P-value (F-stat)                0.0000\n",
      "Time:                        19:34:32   Distribution:                 chi2(30)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "constant        0.0626     0.0055     11.477     0.0000      0.0519      0.0733\n",
      "cohort_1959    -0.0006     0.0008    -0.7622     0.4459     -0.0022      0.0010\n",
      "cohort_1960     0.0006     0.0008     0.7226     0.4699     -0.0010      0.0022\n",
      "cohort_1961     0.0009     0.0009     1.0223     0.3067     -0.0008      0.0027\n",
      "cohort_1962     0.0015     0.0009     1.8017     0.0716     -0.0001      0.0032\n",
      "naturalized     0.1114     0.1752     0.6359     0.5248     -0.2319      0.4547\n",
      "indigenous     -0.0618     0.1280    -0.4825     0.6295     -0.3127      0.1892\n",
      "dist2           0.0238     0.0162     1.4668     0.1424     -0.0080      0.0557\n",
      "dist3          -0.0570     0.0397    -1.4368     0.1508     -0.1347      0.0207\n",
      "dist4           0.0212     0.0228     0.9274     0.3537     -0.0236      0.0659\n",
      "dist5          -0.0017     0.0416    -0.0400     0.9681     -0.0832      0.0799\n",
      "dist6          -0.0394     0.0149    -2.6391     0.0083     -0.0686     -0.0101\n",
      "dist7          -0.0182     0.0239    -0.7635     0.4451     -0.0651      0.0286\n",
      "dist8           0.0359     0.0218     1.6449     0.1000     -0.0069      0.0786\n",
      "dist9           0.0065     0.0318     0.2032     0.8390     -0.0558      0.0687\n",
      "dist10         -0.0034     0.0310    -0.1093     0.9129     -0.0641      0.0574\n",
      "dist11         -0.0080     0.0465    -0.1733     0.8625     -0.0991      0.0830\n",
      "dist12         -0.0087     0.0464    -0.1877     0.8511     -0.0997      0.0823\n",
      "dist13          0.0249     0.0209     1.1900     0.2341     -0.0161      0.0659\n",
      "dist14         -0.0039     0.0242    -0.1593     0.8734     -0.0514      0.0437\n",
      "dist15          0.2151     0.0428     5.0242     0.0000      0.1312      0.2989\n",
      "dist16          0.0333     0.0353     0.9430     0.3457     -0.0359      0.1024\n",
      "dist17          0.0595     0.0256     2.3189     0.0204      0.0092      0.1097\n",
      "dist18         -0.0049     0.0292    -0.1664     0.8678     -0.0622      0.0524\n",
      "dist19          0.0265     0.0434     0.6119     0.5406     -0.0585      0.1115\n",
      "dist20          0.1790     0.0685     2.6128     0.0090      0.0447      0.3133\n",
      "dist21          0.0041     0.0154     0.2683     0.7885     -0.0261      0.0344\n",
      "dist22         -0.0481     0.0256    -1.8735     0.0610     -0.0983      0.0022\n",
      "dist23          0.0007     0.1365     0.0054     0.9957     -0.2668      0.2683\n",
      "dist24          0.0160     0.0214     0.7508     0.4528     -0.0258      0.0579\n",
      "sm              0.0027     0.0008     3.2178     0.0013      0.0011      0.0043\n",
      "===============================================================================\n",
      "\n",
      "Endogenous: sm\n",
      "Instruments: highnumber\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "iv = IV2SLS(y, df_reg[constant + cohorts[29: 33] + origin + districts], df_reg['sm'], df_reg['highnumber'])\n",
    "rslts = iv.fit()\n",
    "print(f'2SLS Results. Cohort, origin and district controls included.')\n",
    "print(rslts)\n",
    "#print('Coefficient estimate for Conscription (sm).')\n",
    "#print(round(rslts.params[0], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "#print()\n",
    "#print('White robust standard error Conscription (sm).')\n",
    "#print(round(rslts.HC0_se[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0431336746797286"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslts.params['sm']/rslts.params['constant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highnumber\n",
       "0.0    0.068094\n",
       "1.0    0.069769\n",
       "Name: crimerate, dtype: float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg.crimerate.groupby(df_reg.highnumber).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 4 columns (5) - (7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column (5): 1929 - 1965 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Since we are considering data from 1929 through 1965, we need to adapt the data frame.\n",
    "df_cohorts_29_65 = df[df.cohort > 1928][df.cohort < 1966][highnumber + constant + cohorts + crimerate].copy().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohorts_29_65[highnumber + constant + cohorts]\n",
    "y = df_cohorts_29_65.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results. Cohort controls only.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.0006\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0003\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "rslts = model.fit()\n",
    "\n",
    "print(f'OLS Results. Cohort controls only.')\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params['highnumber'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se['highnumber'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column (6): 1929 - 1955 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Since we are considering data from 1929 through 1955, we need to adapt the data frame.\n",
    "df_cohorts_29_55 = df[df.cohort > 1928][df.cohort < 1956].copy()\n",
    "df_cohorts_29_55 = df_cohorts_29_55[highnumber + constant + cohorts + crimerate]\n",
    "df_cohorts_29_55 = df_cohorts_29_55.dropna(axis=0)  # Drop NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohorts_29_55[highnumber + constant + cohorts]\n",
    "y = df_cohorts_29_55.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results. Cohort controls only.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.0003\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0004\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "rslts = model.fit()\n",
    "\n",
    "print(f'OLS Results. Cohort controls only.')\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params['highnumber'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se['highnumber'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column (7): 1958 - 1965 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Since we are considering data from 1958 through 1965, we need to adapt the data frame.\n",
    "df_cohorts_58_65 = df[df.cohort > 1957][df.cohort < 1966].copy()\n",
    "df_cohorts_58_65 = df_cohorts_58_65[highnumber + constant + cohorts[29:36] + crimerate]\n",
    "df_cohorts_58_65 = df_cohorts_58_65.dropna(axis=0)  # Drop NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohorts_58_65[highnumber + constant + cohorts[29:36]]\n",
    "y = df_cohorts_58_65.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results. Cohort controls only.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.0012\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0004\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "rslts = model.fit()\n",
    "\n",
    "print(f'OLS Results. Cohort controls only.')\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params['highnumber'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se['highnumber'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare OLS (appendix table A.4) and 2SLS (table 4, columns 3 & 4) results: in which direction does the bias go?\n",
    "- Get 'Percent change' (see notes on table 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 5 - Estimated Impact of Conscription on Crime Rates for Peacetime versus Wartime Service and 1-Year versus 2-Year Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 5 column (1) & (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (1): 1929 - 1965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_29_65 = df[df.cohort > 1928][df.cohort < 1966][highnumber + hn_malvinas + constant + cohorts[0:36] + crimerate].copy().dropna(axis=0)\n",
    "X = df_29_65[highnumber + hn_malvinas + constant + cohorts[0:36]].copy()\n",
    "y = df_29_65.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.000475\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0003\n",
      "\n",
      " Coefficient estimate for Eligible during Malvinas War (malvinas).\n",
      "0.0015\n",
      "\n",
      " White robust standard error Draft eligible (malvinas).\n",
      "0.0009\n",
      "\n",
      " Number of observations: 34904\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "rslts = model.fit()\n",
    "print(f'OLS Results.')\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params['highnumber'], 6))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se['highnumber'], 4))\n",
    "print('\\n Coefficient estimate for Eligible during Malvinas War (malvinas).')\n",
    "print(round(rslts.params['hn_malvinas'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (malvinas).')\n",
    "print(round(rslts.HC0_se['hn_malvinas'], 4))\n",
    "print(f'\\n Number of observations: {len(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (2): 1958 - 1965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_58_65 = df[df.cohort > 1957][df.cohort < 1966][highnumber + hn_malvinas + constant + cohorts[29:36] + crimerate].copy().dropna(axis=0)\n",
    "X = df_58_65[highnumber + hn_malvinas + constant + cohorts[29:36]].copy()\n",
    "y = df_58_65.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.0009\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0005\n",
      "\n",
      " Coefficient estimate for Eligible during Malvinas War (hn_malvinas).\n",
      "0.0011\n",
      "\n",
      " White robust standard error Eligible during Malvinas War (hn_malvinas).\n",
      "0.001\n",
      "\n",
      " Number of observations: 7928\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "rslts = model.fit()\n",
    "print(f'OLS Results.')\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params['highnumber'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se['highnumber'], 4))\n",
    "print('\\n Coefficient estimate for Eligible during Malvinas War (hn_malvinas).')\n",
    "print(round(rslts.params['hn_malvinas'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Eligible during Malvinas War (hn_malvinas).')\n",
    "print(round(rslts.HC0_se['hn_malvinas'], 4))\n",
    "print(f'\\n Number of observations: {len(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 5 column (3) & (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (3): 1928 - 1965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_29_65 = df[df.cohort > 1928][df.cohort < 1966][highnumber + navy + constant + cohorts[0:36] + crimerate].copy().dropna(axis=0)\n",
    "X = df_29_65[highnumber + navy + constant + cohorts[0:36]].copy()\n",
    "y = df_29_65.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.000539\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0003\n",
      "\n",
      " Coefficient estimate for Eligible for Navy (navy).\n",
      "0.0007\n",
      "\n",
      " White robust standard error Eligible for Navy (navy).\n",
      "0.0003\n",
      "\n",
      " Number of observations: 34904\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "rslts = model.fit()\n",
    "print('OLS Results.')\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params['highnumber'], 6))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se['highnumber'], 4))\n",
    "print('\\n Coefficient estimate for Eligible for Navy (navy).')\n",
    "print(round(rslts.params['navy'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Eligible for Navy (navy).')\n",
    "print(round(rslts.HC0_se['navy'], 4))\n",
    "print(f'\\n Number of observations: {len(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column (4): 1958 - 1965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_58_65 = df[df.cohort > 1957][df.cohort < 1966][highnumber + navy + constant + cohorts[29:36] + crimerate].copy().dropna(axis=0)\n",
    "X = df_58_65[highnumber + navy + constant + cohorts[29:36]].copy()\n",
    "y = df_58_65.loc[:, 'crimerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results.\n",
      "\n",
      " Coefficient estimate for Draft eligible (highnumber).\n",
      "0.001\n",
      "\n",
      " White robust standard error Draft eligible (highnumber).\n",
      "0.0004\n",
      "\n",
      " Coefficient estimate for Eligible for Navy (navy).\n",
      "0.0011\n",
      "\n",
      " White robust standard error Eligible for Navy (navy).\n",
      "0.0006\n",
      "\n",
      " Number of observations: 7928\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "rslts = model.fit()\n",
    "print(f'OLS Results.')\n",
    "print('\\n Coefficient estimate for Draft eligible (highnumber).')\n",
    "print(round(rslts.params['highnumber'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Draft eligible (highnumber).')\n",
    "print(round(rslts.HC0_se['highnumber'], 4))\n",
    "print('\\n Coefficient estimate for Eligible for Navy (navy).')\n",
    "print(round(rslts.params['navy'], 4))  # Get array of these values (not rounded) by adding .values.\n",
    "print('\\n White robust standard error Eligible for Navy (navy).')\n",
    "print(round(rslts.HC0_se['navy'], 4))\n",
    "print(f'\\n Number of observations: {len(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an error in the do.-file provided.\n",
    "> areg crimerate highnumber navy if cohort > 1956 & cohort < 1966, absorb(cohort) robust\n",
    "\n",
    "So, they do the analysis for the cohort 195**7** to 1965, although they state that the cohort of 1957 was not drafted at all. The above figures do not differ from the one's presented in table 5 column 4. This is probably due to the handling of NaNs. If rows containing NaNs are dropped in Stata then the rows satisfying cohort==1957 are dropped entirely, since they have NaNs for *highnumber*. That is why the number of observations does not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    1000\n",
       "Name: highnumber, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cohort == 1957].highnumber.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Complementary Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get [back to top](#Content-of-this-Notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 6 - Estimated Impact of Conscription on Crime rates, by Type of Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galiani et al. use data on types of crime at the cohort-ID level to analyse the effect of military service on types of crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_reg = df[df.cohort > 1957][df.cohort < 1963].copy()\n",
    "# Dependent variable: crime \"use of weapons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highnumber\n",
       "0.0    0.001312\n",
       "1.0    0.000511\n",
       "Name: arms, dtype: float32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arms'].groupby(df.highnumber).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arms\n",
      "Conscription   0.00013\n",
      "Std. error     0.00011\n",
      "Percent change 0.14\n",
      "Observations   5000\n",
      "Method         2SLS \n",
      "\n",
      "Property\n",
      "Conscription   0.00082\n",
      "Std. error     0.00034\n",
      "Percent change 0.11\n",
      "Observations   5000\n",
      "Method         2SLS \n",
      "\n",
      "Sexual\n",
      "Conscription   0.00013\n",
      "Std. error     0.00009\n",
      "Percent change 0.2\n",
      "Observations   5000\n",
      "Method         2SLS \n",
      "\n",
      "Murder\n",
      "Conscription   -0.00007\n",
      "Std. error     0.00010\n",
      "Percent change -0.082\n",
      "Observations   5000\n",
      "Method         2SLS \n",
      "\n",
      "Threat\n",
      "Conscription   0.00022\n",
      "Std. error     0.00014\n",
      "Percent change 0.14\n",
      "Observations   5000\n",
      "Method         2SLS \n",
      "\n",
      "Drug\n",
      "Conscription   -0.00009\n",
      "Std. error     0.00014\n",
      "Percent change -0.071\n",
      "Observations   5000\n",
      "Method         2SLS \n",
      "\n",
      "Whitecollar\n",
      "Conscription   0.00064\n",
      "Std. error     0.00021\n",
      "Percent change 0.21\n",
      "Observations   5000\n",
      "Method         2SLS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_sm = []\n",
    "pval_sm = []\n",
    "std_sm = []\n",
    "for crime in ['arms', 'property', 'sexual', 'murder', 'threat', 'drug', 'whitecollar']:\n",
    "    print(crime.capitalize())\n",
    "    y = df_reg.loc[:, crime]\n",
    "    rslts = IV2SLS(y, df_reg[constant + cohorts[29: 33]], df_reg['sm'], df_reg['highnumber']).fit()\n",
    "    # Get percent change.\n",
    "    ineligible_mean = df_reg[df_reg.highnumber == 0][crime].mean()  # Mean crime rate of ineligible ID-groups.\n",
    "    change = (rslts.params.sm/ineligible_mean)\n",
    "    print(f'Conscription   {rslts.params.sm:.5f}')  # By default White standard errors.\n",
    "    print(f'Std. error     {rslts.std_errors.sm:.5f}')\n",
    "    print(f'Percent change {change:.2}')\n",
    "    print(f'Observations   {len(y)}')\n",
    "    print(f'Method         2SLS \\n')\n",
    "    #rgrssn = [rslts.params.sm, rslts.std_errors.sm, change, len(y)]\n",
    "    reg_sm.append(rslts.params.sm)\n",
    "    pval_sm.append(rslts.pvalues.sm)\n",
    "    std_sm.append(rslts.std_errors.sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22889130189671825,\n",
       " 0.014654646413069461,\n",
       " 0.1519993907367172,\n",
       " 0.4633357055443452,\n",
       " 0.11980678910133369,\n",
       " 0.5083596624904461,\n",
       " 0.0024662899339198407]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00013415404306115798,\n",
       " 0.0008236228235556572,\n",
       " 0.00013402104531121204,\n",
       " -7.335601769189928e-05,\n",
       " 0.0002203136231146846,\n",
       " -8.964112157497112e-05,\n",
       " 0.0006385308994128307]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(pval):\n",
    "    if pval <= 0.01:\n",
    "        star = \"***\"\n",
    "    elif pval <= 0.05:\n",
    "        star = \"**\"\n",
    "    elif pval <= 0.1:\n",
    "        star = \"*\"\n",
    "    else:\n",
    "        star = \" \"\n",
    "    \n",
    "    return star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTable 6 - Estimated Impact of Conscription on Crime rates, by Type of Crime\u001b[0m\n",
      "________________________________________________________________________________________________________________________\n",
      "Dependent         Weapons     Property   Sexual Attack       Murder       Threat   Drug Trafficking   White Collar             \n",
      "Cohort          1958-1962    1958-1962    1958-1962    1958-1962    1958-1962    1958-1962    1958-1962             \n",
      "                      (1)          (2)          (3)          (4)          (5)          (6)          (7)             \n",
      "________________________________________________________________________________________________________________________\n",
      "Conscription   \u001b[1m   0.00013   \u001b[0m\u001b[1m   0.00082** \u001b[0m\u001b[1m   0.00013   \u001b[0m\u001b[1m  -0.00007   \u001b[0m\u001b[1m   0.00022   \u001b[0m\u001b[1m  -0.00009   \u001b[0m\u001b[1m   0.00064***\u001b[0m\n",
      "\n",
      "    0.0001       0.0003       0.0001       0.0001       0.0001       0.0001       0.0002   "
     ]
    }
   ],
   "source": [
    "print('\\033[1m' 'Table 6 - Estimated Impact of Conscription on Crime rates, by Type of Crime' '\\033[0m')\n",
    "print(120*'_')\n",
    "# Header.\n",
    "print('{:<15s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}'\\\n",
    "      .format('Dependent', 'Weapons', \"\", 'Property', \"\", 'Sexual Attack', \"\", 'Murder', \"\", 'Threat', \"\", 'Drug Trafficking', \"\", \\\n",
    "            'White Collar', '', ''))\n",
    "print('{:<15s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}'\\\n",
    "      .format('Cohort', '1958-1962', '', \"1958-1962\", '', \"1958-1962\", '', \"1958-1962\", '', \"1958-1962\", '', \"1958-1962\", '', \\\n",
    "            \"1958-1962\", '', ''))\n",
    "print('{:<15s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}{:<3s}{:>10s}'\\\n",
    "      .format('', '(1)', '', '(2)', '', '(3)', '', '(4)', '', '(5)', '', '(6)', '', \\\n",
    "            '(7)', '', ''))\n",
    "print(120*'_')\n",
    "\n",
    "\n",
    "for i in range(len(reg_sm)):\n",
    "    if i == 0:\n",
    "        print('{:<15s}'.format(\"Conscription\"), end=\"\")\n",
    "    print('\\033[1m' '{:>10.5f}{:<3s}' '\\033[0m'.format(reg_sm[i], significance(pval_sm[i])), end=\"\")\n",
    "print('\\n')\n",
    "for i in range(len(std_sm)):\n",
    "    print('{:>10.4f}{:<3s}'.format(std_sm[i], ''), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 0.3334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('title')\n",
    "print(100*'_')\n",
    "print('Cohort            1958-1962     1958-1962     1958-1962     1958-1962   ')\n",
    "print('                     (1)           (2)           (3)           (4)      ')\n",
    "print(100*'_')\n",
    "print(f'Draft eligible      {y}         {y}         {y}         {y}')\n",
    "print(f'                   ({y})       ({y})       ({y})       ({y})')\n",
    "print(f'Conscription')\n",
    "print(f'Percent change')\n",
    "print(f'Controls')\n",
    "print(f'Observations')\n",
    "print(f'Method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Online Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get [back to top](#Content-of-this-Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the online appendix I replicate the failure rates of medical examination and the relationship between the conditional probability of serving in the military and the draft lottery numbers. Both are done for the core cohorts of the analysis 1958-1962. They are interesting since they show the behavioural response to the varying probability of being drafted into the military."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extensions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get [back to top](#Content-of-this-Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas the impact of conscription and the draft lottery is very pronounced, this is not the case for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local IV would have been an appealing extension to this model. Unfortunately this is possible only, if one observes the strength of the instrument on selecting into the treatment. This is not the case here. The instrument *Draft Eligible* is a dummy variable, thus, there is no way of getting a measure of how large the incentives are to actually selecting into the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Local IV instead of conventional IV. See [lecture](https://microeconometrics.readthedocs.io/lectures/generalized-roy-model/notebook.html#Estimation-strategies) from 16 June 2020.\n",
    "- Bootstrapped standard errors? Are they biased in case of IV with finite no. of obs.? See [this](https://core.ac.uk/download/pdf/6387257.pdf) paper for details.\n",
    "- IV biased in finite samples. (Especially if weak instrument.)\n",
    "- Also get residuals (correct procedure of IV?) from first stage and plot these on crimerate.\n",
    "- Nonparametric test\n",
    "- \"If I don't see the effect in the raw data, I don't believe it.\" - Some nice graphs of raw data.\n",
    "- Simulation: what if more able individuals can also avoid conscription more effectively (i.e. fail med. exam. purposely); compare to direction of bias.\n",
    "- Simulation: what if people with high draft number are not taken into account for a job since they are probably drafted?\n",
    "- Formal LM participation not a good proxy in Argentina? Are there other measures available!? Look for data!\n",
    " - Maybe some groups that are being drafted are actually participating in the informal LM more often. But formal LM participation is an economic outcome in itself.\n",
    "- Determinants of failure rate of med. ex.: in which districts, did individ.s with high prob. of being drafted fail med. ex.? Combine this with data on districts to evaluate whether findings biased. (Probably not a good robustness test.)\n",
    "- Robustness test(?): data on youth crimes?\n",
    "- p. 122: Cohorts in '56 & '57 were not called at all (change from 21 to 18 years start age military service) - Could I use this for robustness test? (Galiani et al. already did so.)\n",
    "- p. 129: Leave out obs close to cutoff.\n",
    "- p. 130: Exog. of IV \"test\": divide data for low draft no.s into two sets: pseudo test. Vary cutoff number.\n",
    "- p. 131: Cohort 1976 was assigend but never needed to serve in the military (abolishment of conscription); for pseudo test: use other cutoffs or sequence of cutoffs.\n",
    "- Check papers that cited Galiani et al. 2011.\n",
    "- Note on direction of bias\n",
    "- Simulation: weak instrument\n",
    "- More robustness checks.\n",
    "- Advanced statistical tests.\n",
    "- Read: my notes on lectures on 'Self-selection,...', 'IV', 'Gen. Roy Model', 'Causal Explanations', 'RDD'\n",
    "- Exclude uutliers (see df_regression.plot.scatter(x='fitted_conscription', y='crimerate'))\n",
    "- Cohort-wise TSLS (as in table 3 columns 2-6)\n",
    "- What if socioeconomic background affects conscription but also the probability of mental disorders (which in turn affect crime rate directly but also through lower labour market experience)? - Simulation study\n",
    "- Table 5 with 1958-1962 and do it as in table 4: use 2SLS instead of intention-to-treat and OLS!\n",
    "- Effect of conscription may well be a question on in which military one has served.\n",
    " - Knowing what causes potentially detrimental or positive effects of serving in the military is vital if one wants to fully compensate veterans or if a policy maker considers the implementation of compulsory military service.\n",
    "- Biased RDD irgendwas wert?\n",
    "- Other literature: the effect may be country dependent; military service is not the same in Argentina as in Denmark or Germany.\n",
    " - Maybe effect between democratic and autocratic countries.\n",
    "- Leave out potential outliers.\n",
    " - which method applicable?\n",
    "- In table 6 include more controls than only cohort dummies.\n",
    "- Get variables for army & air force for core cohorts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot crime rate for each draft number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in years:\n",
    " #   df[df.cohort == i].plot.scatter(x='draftnumber', y='crimerate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in years:\n",
    " #   df[df.cohort == i].plot.scatter(x='highnumber', y='crimerate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_regression.fitted_conscription.value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_regression.plot.scatter(x='fitted_conscription', y='crimerate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in years:\n",
    " #   df[df.cohort == i].plot.scatter(x='sm', y='crimerate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure A.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_plot(bin_num, ylim, years):\n",
    "    '''\n",
    "    Returns plots for crime rate. To smooth out fluctuations, data can be partitioned into bin_num bins. For each bin the mean\n",
    "    of crime rate is computed. Number of plots returned depends on number of cohorts desired.\n",
    "    bin_num: int, number of bins\n",
    "    ylim: list/2-tuple, range of y-axis of plots\n",
    "    years: list of cohorts\n",
    "    '''\n",
    "    bins = np.linspace(0, 1000, bin_num+1)\n",
    "    for i in years:\n",
    "        binned_stats = stats.binned_statistic(x=df[df.cohort == i].draftnumber, values=df[df.cohort == i].enfdummy, \n",
    "                                              statistic='mean', bins=bins)\n",
    "        df_bin = pd.DataFrame()\n",
    "        df_bin['Crime rate'] = binned_stats.statistic\n",
    "        df_bin['Draftnumber'] = bins[1: bin_num+1]\n",
    "        df_bin.plot.line(x='Draftnumber', y='Crime rate', title=f'Crime Rates for Cohort {i}', ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binned_plot(bin_num=1000, ylim=[0, 0.15], years = list(range(1958, 1963, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_plot(bin_num=200, ylim=[0.04, 0.115], years = list(range(1958, 1963, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in years:\n",
    "    df[df.cohort == i].plot.scatter(x='draftnumber', y='enfdummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure A.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in years:\n",
    "    df[df.cohort == i].plot.scatter(x='draftnumber', y='sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Extended \"Testing\" of Exogeneity of Instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galinani et al. (2011) provide suggestive evidence of the plausibility of the exclusion restriction of the instrument *draft eligible*. Of course there are no statistical tests that really test the exogeneity of the instrument. They present some evidence that further supports the exogeneity of the instrument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Core cohorts: 1958 - 1962"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galiani et al. (2011) use the group of draft-exempt ID groups for each core cohort, create fake cutoff numbers, assigning each ID group to control and treatment, and test whether crime rates differ. For the fake cutoff number they use the median of the ID. Galiani et al. (2011) do not include the results of their tests neither in the paper nor the online appendix.\n",
    "I extend the analysis by varying the fake cutoff number and by applying the same procedure on the observations that were draft eligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fake_cutoff(df, highnumber):\n",
    "    '''\n",
    "    df data frame\n",
    "    highnumber = 1 or highnumber = 0 test for draft eligible and exempt group\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for c in range(1958, 1963, 1):\n",
    "        print(f'Cohort {c}')\n",
    "        dfa = df[df.cohort == c][df.highnumber == highnumber][['crimerate', 'draftnumber']].copy()\n",
    "        for q in np.linspace(0.1, 1, 9,endpoint=False):\n",
    "            fake_cutoff = dfa.draftnumber.quantile(q)\n",
    "            test = stats.ttest_ind(dfa.crimerate[dfa.draftnumber > fake_cutoff], dfa.crimerate[dfa.draftnumber < fake_cutoff],\n",
    "                           axis=0, equal_var=False, nan_policy='propagate')\n",
    "            print(f'Quantile = {q: .1f}', f'\\n t-test = {test.statistic:.4f}', f'\\n p-value = {test.pvalue:.4f}')\n",
    "            if test.pvalue < 0.1 and test.pvalue > 0.05:\n",
    "                print('*')\n",
    "            elif test.pvalue <= 0.05 and test.pvalue > 0.01:\n",
    "                print('**')\n",
    "            elif test.pvalue <= 0.01:\n",
    "                print('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_fake_cutoff(df=df, highnumber=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutoffs implied by data set (integere associated with highnumber==0).\n",
    "for c in range(1958, 1963, 1):\n",
    "    print(df[df.cohort == c].highnumber.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Cohorts 1956 and 1957"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohorts of 1956 and 1957 were not drafted into the military due to a change in entry age of military service. According to Galiani et al. (2011), individuals knew well in advance they would not be coerced of entering military service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Cohort 1976 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galiani et al. (2011) use the fact that the cohort of 1976 was assigned draft numbers but never actually served in the military. The draft numbers were assigned on May 27, 1994, but on August 31, 1994 conscription was abolished (ibid, p. 131). The authors employ the cutoff number of the cohort of 1975 and find no effect on crime rates. They argue that this ruled out all concerns that the instrument has an independent effect on crime rates (see section 1 for a discussion of potential pitfalls). Garano (2010) states that conscription was abolished because of a murder on a soldier on May 6, 1994 (p. 174). Therefore I do not find their argumentation based on the usage of the cohort of 1976 convincing and their instrument may be compromised. I extend their analysis by using a range of cutoff numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Robustness checks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Table 6 with Controls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In table 6 include more controls than only cohort dummies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Table 4 for each Cohort Separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get table 4 for each cohort from 1958-1969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 5 with Army Dummy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In table 5, columns 3 and 4, Galiani et al. (2011) use the data on military service in the navy. They use an indicator variable stating whether cohort-ID group *ci* was eligible for service in the navy or not. I extend upon their analysis by including a dummy for service in the army as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.military.groupby(df.navy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.navy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.navy, df.military, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.navy.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get navy cutoff numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958 \n",
      " 0.0    863\n",
      "1.0    137\n",
      "Name: navy, dtype: int64\n",
      "1959 \n",
      " 0.0    888\n",
      "1.0    112\n",
      "Name: navy, dtype: int64\n",
      "1960 \n",
      " 0.0    878\n",
      "1.0    122\n",
      "Name: navy, dtype: int64\n",
      "1961 \n",
      " 0.0    878\n",
      "1.0    122\n",
      "Name: navy, dtype: int64\n",
      "1962 \n",
      " 0.0    895\n",
      "1.0    105\n",
      "Name: navy, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in range(1958, 1963, 1):\n",
    "    print(f'{c} \\n', df[df.cohort == c].navy.value_counts())  # Numbers attached to navy==0 give respective cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.enfdummy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('data/baseB.dta')\n",
    "baseb = pd.read_stata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('data/baseC.dta')\n",
    "basec = pd.read_stata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basec.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('data/baseA.dta')\n",
    "basea = pd.read_stata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('data/Compliers.dta')\n",
    "compliers = pd.read_stata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compliers.proporcinqueladebahacer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galiani et al. (2011) do not report F-tests of the applicability of *draft eligible* as an instrument for *conscription*. Having a strong instrument is crucial for the reliability of the instrumental variable approach. For the implications of a weak instrument, see section 1.2. Stock and Yogo (2002) find that an F-test statistic should be at least as large as 10, in order to rule out the possibility of a weak instrument. Better results are obtained if the F-test statistic is larger than 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get conditional means of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.6587/0.0012)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Critical Assessment of Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Same criticism to Angrist (1990) by Rosenzweig & Wolpin (2000) applicable to this study if mechanism thorugh labour market\n",
    " - Positive: they consider a deeper mechanism of conscription on crimerate. But they still go not deep enough.\n",
    " - Effect of 'navy': what if navy has otherwise detrimental effects that lead to crime rate to incr.?\n",
    " - Problems of intention-to-treat estimates\n",
    "  - read sth up for this\n",
    "  - check rsults: which crimes are committed more often? Is this in line with other research? Plausibility of the results.\n",
    " - Defiers: Authors do not argue why defiers are improbable; this is an assumption, nothing else.\n",
    " - Authors state that white collar and crimes against property should be larger if conscription detrimental effect on lM outcomes (p. 133). But same should apply to drug trafficking, since it also serves a pecuniary purpose, I'd argue.\n",
    " - Effect of navy: maybe other detrimental effects of serving in the navy. Implicit assump.: navy service same as air force and army on crime rates except for duration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get [back to top](#Content-of-this-Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angrist, Joshua D. 1990. \"Lifetime Earnings and the Vietnam Era Draft Lottery: Evidence from Social Security Administrative Records.\". *American Economic Review*, 80 (3): 313-336\n",
    "\n",
    "Angrist, Joshua D., Guido W. Imbens, and Donald B. Rubin. 1996. \"Identification of Causal Effects Using Instrumental Variables.\" *Journal of the American Statistical Association*, 91:434, 444-455\n",
    "\n",
    "Galiani, Sebastian, Martín A. Rossi, and Ernesto Schargrodsky. 2011. \"Conscription and Crime: Evidence from the Argentine Draft Lottery.\" *American Economic Journal: Applied Economics*, 3 (2): 119-36.\n",
    "[DOI: 10.1257/app.3.2.119](http://dx.doi.org/10.1257/app.3.2.119)\n",
    "\n",
    "Garano, Santiago. 2010. \"The Opposition Front against Compulsory Military Service: The Conscription Debate and Human-Rights Activism in Post-Conscription Debate and Human-Rights Activism in Post-dictatorship Argentina dictatorship Argent.\" *Genocide Studies and Prevention: An International Journal*, 5 (2): 174-190\n",
    "\n",
    "Heckman, James. 1997. \"Instrumental Variables: A Study of Implicit Behavioral Assumptions Used in MakingProgram Evaluations.\" *Journal of Human Resources*, 32 (3), 441-462\n",
    "\n",
    "Imbens, Guido and Joshua Angrist. 1994. \"Identification and Estimation of Local Average Treatment Effects.\" *Econometrica*, 62 (2): 467-75.\n",
    "            \n",
    "Pearl, J. 2014. \"Causality.\" Cambridge, England: *Cambridge University Press*.\n",
    "\n",
    "Rosenzweig, Mark, R., and Kenneth I. Wolpin. 2000. \"Natural \"Natural Experiments\" in Economics.\" *Journal of Economic Literature*, 38 (4): 827-874.\n",
    "\n",
    "Stock, James H., and Motohiro Yogo. 2002. \"Testing for Weak Instruments in Linear IV Regression.\" *NBER Technical Working Paper*, No. 284\n",
    "\n",
    "Winship, C., and S. L. Morgan. 2007. \"Counterfactuals and causal inference: Methods and principles for social research.\" Cambridge, England: *Cambridge University Press*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
